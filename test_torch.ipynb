{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/glee1228/netVLad_keras/blob/master/test_torch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "16b499aa-0826-4188-bf8b-7b792f109e70",
        "id": "ylXCBFtLuorO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from torch.autograd import Variable\n",
        "from torchvision import models\n",
        "\n",
        "from tensorflow import keras\n",
        "from keras.preprocessing import image\n",
        "\n",
        "import PIL\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import svm, datasets, metrics"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "5af81dda-de08-4d2a-907c-ac51f92314cc",
        "id": "ToNiCoiVuorX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "torch.manual_seed(777)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f24e75472d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ekD3HEdBzND",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip install tensorboardcolab\n",
        "# from tensorboardcolab import TensorBoardColab\n",
        "# tb = TensorBoardColab()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "81bc2509-d057-4c2d-eba2-8b7d3d1d964c",
        "id": "xTWw139juord",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "if os.path.exists('/content/gdrive')==False:\n",
        "    drive.mount('/content/gdrive')\n",
        "    print('Google Drive is mounted\\n')\n",
        "else:\n",
        "    print('Google Drive is already mounted\\n')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n",
            "Google Drive is mounted\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVXFtGxtVGPx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ckpt_path = '/content/gdrive/My Drive/AILeader_Dataset/ckpt'\n",
        "test_path = '/content/gdrive/My Drive/AILeader_Dataset/test'\n",
        "history_path = '/content/gdrive/My Drive/AILeader_Dataset/history_train.csv'\n",
        "\n",
        "epochs = 50\n",
        "batch_size = 256\n",
        "model_name = 'resnet18' #'resnet18','resnet50','resnet101','alexnet','vgg16','vgg19','densenet121','densenet161','mobilenet','squeezenet'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uX8brvFTwhwQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_save_name = '{}_model_{}_{}.pt'.format(model_name,epochs-1,batch_size)\n",
        "# model_save_name = 'model_49.pt'\n",
        "model_load_path = os.path.join(ckpt_path,model_save_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "reG3WirNxxZr",
        "colab_type": "code",
        "outputId": "65098a43-8387-454f-e443-32642685d02a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "refer_num_Images = 0\n",
        "for path, dirs, files in os.walk(test_path):\n",
        "  for directory in dirs:\n",
        "    files_len=len(os.listdir(os.path.join(path,directory)))\n",
        "    print(files_len)\n",
        "    refer_num_Images+=files_len\n",
        "print('Total Number of Images(dataset)  : {}'.format(refer_num_Images))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "24\n",
            "7\n",
            "14\n",
            "15\n",
            "23\n",
            "Total Number of Images(dataset)  : 83\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aitx5dLT4BkI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## OOM으로 인한 쿼리 이미지 수 축소\n",
        "## train 데이터셋(366장)으로 test할 경우  refer_num_Images != query_num_Images\n",
        "## test 데이터셋(81장)으로 test 할 경우 refer_num_Images == query_num_Images\n",
        "query_num_Images = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ByNd9eMsFYn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NetVLAD(nn.Module):\n",
        "    \"\"\"NetVLAD layer implementation\"\"\"\n",
        "\n",
        "    def __init__(self, num_clusters=7, dim=128, alpha=100.0,\n",
        "                 normalize_input=True):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            num_clusters : int\n",
        "                The number of clusters\n",
        "            dim : int\n",
        "                Dimension of descriptors\n",
        "            alpha : float\n",
        "                Parameter of initialization. Larger value is harder assignment.\n",
        "            normalize_input : bool\n",
        "                If true, descriptor-wise L2 normalization is applied to input.\n",
        "        \"\"\"\n",
        "        super(NetVLAD, self).__init__()\n",
        "        self.num_clusters = num_clusters\n",
        "        self.dim = dim\n",
        "        self.alpha = alpha\n",
        "        self.normalize_input = normalize_input\n",
        "        self.conv = nn.Conv2d(dim, num_clusters, kernel_size=(1, 1), bias=True)\n",
        "        self.centroids = nn.Parameter(torch.rand(num_clusters, dim))\n",
        "        self._init_params()\n",
        "\n",
        "    def _init_params(self):\n",
        "        self.conv.weight = nn.Parameter(\n",
        "            (2.0 * self.alpha * self.centroids).unsqueeze(-1).unsqueeze(-1)\n",
        "        )\n",
        "        self.conv.bias = nn.Parameter(\n",
        "            - self.alpha * self.centroids.norm(dim=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        N, C = x.shape[:2]\n",
        "\n",
        "        if self.normalize_input:\n",
        "            x = F.normalize(x, p=2, dim=1)  # across descriptor dim\n",
        "\n",
        "        # soft-assignment\n",
        "        soft_assign = self.conv(x).view(N, self.num_clusters, -1)\n",
        "        soft_assign = F.softmax(soft_assign, dim=1)\n",
        "\n",
        "        x_flatten = x.view(N, C, -1)\n",
        "        \n",
        "        # calculate residuals to each clusters\n",
        "        residual = x_flatten.expand(self.num_clusters, -1, -1, -1).permute(1, 0, 2, 3) - \\\n",
        "            self.centroids.expand(x_flatten.size(-1), -1, -1).permute(1, 2, 0).unsqueeze(0)\n",
        "        residual *= soft_assign.unsqueeze(2)\n",
        "        vlad = residual.sum(dim=-1)\n",
        "\n",
        "        vlad = F.normalize(vlad, p=2, dim=2)  # intra-normalization\n",
        "        vlad = vlad.view(x.size(0), -1)  # flatten\n",
        "        vlad = F.normalize(vlad, p=2, dim=1)  # L2 normalize\n",
        "\n",
        "        return vlad\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKzKKFWksfVT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EmbedNet(nn.Module):\n",
        "    def __init__(self, base_model, net_vlad):\n",
        "        super(EmbedNet, self).__init__()\n",
        "        self.base_model = base_model\n",
        "        self.net_vlad = net_vlad\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.base_model(x)\n",
        "        embedded_x = self.net_vlad(x)\n",
        "        return embedded_x\n",
        "      \n",
        "class TripletNet(nn.Module):\n",
        "    def __init__(self, embed_net):\n",
        "        super(TripletNet, self).__init__()\n",
        "        self.embed_net = embed_net\n",
        "\n",
        "    def forward(self, a, p, n):\n",
        "        embedded_a = self.embed_net(a)\n",
        "        embedded_p = self.embed_net(p)\n",
        "        embedded_n = self.embed_net(n)\n",
        "        return embedded_a, embedded_p, embedded_n\n",
        "\n",
        "    def feature_extract(self, x):\n",
        "        return self.embed_net(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fD_yKdlMsZai",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class HardTripletLoss(nn.Module):\n",
        "    \"\"\"Hard/Hardest Triplet Loss\n",
        "    (pytorch implementation of https://omoindrot.github.io/triplet-loss)\n",
        "    For each anchor, we get the hardest positive and hardest negative to form a triplet.\n",
        "    \"\"\"\n",
        "    def __init__(self, margin=0.1, hardest=False, squared=False):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            margin: margin for triplet loss\n",
        "            hardest: If true, loss is considered only hardest triplets.\n",
        "            squared: If true, output is the pairwise squared euclidean distance matrix.\n",
        "                If false, output is the pairwise euclidean distance matrix.\n",
        "        \"\"\"\n",
        "        super(HardTripletLoss, self).__init__()\n",
        "        self.margin = margin\n",
        "        self.hardest = hardest\n",
        "        self.squared = squared\n",
        "\n",
        "    def forward(self, embeddings, labels):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            labels: labels of the batch, of size (batch_size,)\n",
        "            embeddings: tensor of shape (batch_size, embed_dim)\n",
        "        Returns:\n",
        "            triplet_loss: scalar tensor containing the triplet loss\n",
        "        \"\"\"\n",
        "        pairwise_dist = _pairwise_distance(embeddings, squared=self.squared)\n",
        "\n",
        "        if self.hardest:\n",
        "            # Get the hardest positive pairs\n",
        "            mask_anchor_positive = _get_anchor_positive_triplet_mask(labels).float()\n",
        "            valid_positive_dist = pairwise_dist * mask_anchor_positive\n",
        "            hardest_positive_dist, _ = torch.max(valid_positive_dist, dim=1, keepdim=True)\n",
        "\n",
        "            # Get the hardest negative pairs\n",
        "            mask_anchor_negative = _get_anchor_negative_triplet_mask(labels).float()\n",
        "            max_anchor_negative_dist, _ = torch.max(pairwise_dist, dim=1, keepdim=True)\n",
        "            anchor_negative_dist = pairwise_dist + max_anchor_negative_dist * (\n",
        "                    1.0 - mask_anchor_negative)\n",
        "            hardest_negative_dist, _ = torch.min(anchor_negative_dist, dim=1, keepdim=True)\n",
        "\n",
        "            # Combine biggest d(a, p) and smallest d(a, n) into final triplet loss\n",
        "            triplet_loss = F.relu(hardest_positive_dist - hardest_negative_dist + 0.1)\n",
        "            triplet_loss = torch.mean(triplet_loss)\n",
        "        else:\n",
        "            anc_pos_dist = pairwise_dist.unsqueeze(dim=2)\n",
        "            anc_neg_dist = pairwise_dist.unsqueeze(dim=1)\n",
        "\n",
        "            # Compute a 3D tensor of size (batch_size, batch_size, batch_size)\n",
        "            # triplet_loss[i, j, k] will contain the triplet loss of anc=i, pos=j, neg=k\n",
        "            # Uses broadcasting where the 1st argument has shape (batch_size, batch_size, 1)\n",
        "            # and the 2nd (batch_size, 1, batch_size)\n",
        "            loss = anc_pos_dist - anc_neg_dist + self.margin\n",
        "\n",
        "            mask = _get_triplet_mask(labels).float()\n",
        "            triplet_loss = loss * mask\n",
        "\n",
        "            # Remove negative losses (i.e. the easy triplets)\n",
        "            triplet_loss = F.relu(triplet_loss)\n",
        "\n",
        "            # Count number of hard triplets (where triplet_loss > 0)\n",
        "            hard_triplets = torch.gt(triplet_loss, 1e-16).float()\n",
        "            num_hard_triplets = torch.sum(hard_triplets)\n",
        "\n",
        "            triplet_loss = torch.sum(triplet_loss) / (num_hard_triplets + 1e-16)\n",
        "\n",
        "        return triplet_loss\n",
        "\n",
        "\n",
        "def _pairwise_distance(x, squared=False, eps=1e-16):\n",
        "    # Compute the 2D matrix of distances between all the embeddings.\n",
        "\n",
        "    cor_mat = torch.matmul(x, x.t())\n",
        "    norm_mat = cor_mat.diag()\n",
        "    distances = norm_mat.unsqueeze(1) - 2 * cor_mat + norm_mat.unsqueeze(0)\n",
        "    distances = F.relu(distances)\n",
        "\n",
        "    if not squared:\n",
        "        mask = torch.eq(distances, 0.0).float()\n",
        "        distances = distances + mask * eps\n",
        "        distances = torch.sqrt(distances)\n",
        "        distances = distances * (1.0 - mask)\n",
        "\n",
        "    return distances\n",
        "\n",
        "\n",
        "def _get_anchor_positive_triplet_mask(labels):\n",
        "    # Return a 2D mask where mask[a, p] is True iff a and p are distinct and have same label.\n",
        "\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    indices_not_equal = torch.eye(labels.shape[0]).to(device).byte() ^ 1\n",
        "\n",
        "    # Check if labels[i] == labels[j]\n",
        "    labels_equal = torch.unsqueeze(labels, 0) == torch.unsqueeze(labels, 1)\n",
        "\n",
        "    mask = indices_not_equal * labels_equal\n",
        "\n",
        "    return mask\n",
        "\n",
        "\n",
        "def _get_anchor_negative_triplet_mask(labels):\n",
        "    # Return a 2D mask where mask[a, n] is True iff a and n have distinct labels.\n",
        "\n",
        "    # Check if labels[i] != labels[k]\n",
        "    labels_equal = torch.unsqueeze(labels, 0) == torch.unsqueeze(labels, 1)\n",
        "    mask = labels_equal ^ 1\n",
        "\n",
        "    return mask\n",
        "\n",
        "\n",
        "def _get_triplet_mask(labels):\n",
        "    \"\"\"Return a 3D mask where mask[a, p, n] is True iff the triplet (a, p, n) is valid.\n",
        "    A triplet (i, j, k) is valid if:\n",
        "        - i, j, k are distinct\n",
        "        - labels[i] == labels[j] and labels[i] != labels[k]\n",
        "    \"\"\"\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Check that i, j and k are distinct\n",
        "    indices_not_same = torch.eye(labels.shape[0]).to(device).byte() ^ 1\n",
        "    i_not_equal_j = torch.unsqueeze(indices_not_same, 2)\n",
        "    i_not_equal_k = torch.unsqueeze(indices_not_same, 1)\n",
        "    j_not_equal_k = torch.unsqueeze(indices_not_same, 0)\n",
        "    distinct_indices = i_not_equal_j * i_not_equal_k * j_not_equal_k\n",
        "\n",
        "    # Check if labels[i] == labels[j] and labels[i] != labels[k]\n",
        "    label_equal = torch.eq(torch.unsqueeze(labels, 0), torch.unsqueeze(labels, 1))\n",
        "    i_equal_j = torch.unsqueeze(label_equal, 2)\n",
        "    i_equal_k = torch.unsqueeze(label_equal, 1)\n",
        "    valid_labels = i_equal_j * (i_equal_k ^ 1)\n",
        "\n",
        "    mask = distinct_indices * valid_labels   # Combine the two masks\n",
        "\n",
        "    return mask"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qn7-PPiWqwak",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initialize_model(model_name, use_pretrained=True):\n",
        "    # Initialize these variables which will be set in this if statement. Each of these\n",
        "    #   variables is model specific.\n",
        "    base_model = None\n",
        "    dim = 0\n",
        "\n",
        "    if model_name == \"resnet18\":\n",
        "        \"\"\" Resnet18\n",
        "        \"\"\"\n",
        "        encoder = models.resnet18(pretrained=use_pretrained)\n",
        "        base_model = nn.Sequential(\n",
        "        encoder.conv1,\n",
        "        encoder.bn1,\n",
        "        encoder.relu,\n",
        "        encoder.maxpool,\n",
        "        encoder.layer1,\n",
        "        encoder.layer2,\n",
        "        encoder.layer3,\n",
        "        encoder.layer4,\n",
        "        )\n",
        "        dim = list(base_model.parameters())[-1].shape[0]  # last channels (512)\n",
        "        \n",
        "    elif model_name == \"resnet50\":\n",
        "        \"\"\" Resnet50\n",
        "        \"\"\"\n",
        "        encoder = models.resnet50(pretrained=use_pretrained)\n",
        "        base_model = nn.Sequential(\n",
        "        encoder.conv1,\n",
        "        encoder.bn1,\n",
        "        encoder.relu,\n",
        "        encoder.maxpool,\n",
        "        encoder.layer1,\n",
        "        encoder.layer2,\n",
        "        encoder.layer3,\n",
        "        encoder.layer4,\n",
        "        )\n",
        "        dim = list(base_model.parameters())[-1].shape[0]  # last channels (512)\n",
        "    elif model_name == \"resnet101\":\n",
        "        \"\"\" Resnet101\n",
        "        \"\"\"\n",
        "        encoder = models.resnet101(pretrained=use_pretrained)\n",
        "        base_model = nn.Sequential(\n",
        "        encoder.conv1,\n",
        "        encoder.bn1,\n",
        "        encoder.relu,\n",
        "        encoder.maxpool,\n",
        "        encoder.layer1,\n",
        "        encoder.layer2,\n",
        "        encoder.layer3,\n",
        "        encoder.layer4,\n",
        "        )\n",
        "        dim = list(base_model.parameters())[-1].shape[0]  # last channels (512)\n",
        "        \n",
        "    elif model_name == \"alexnet\":\n",
        "        \"\"\" alexnet\n",
        "        \"\"\"\n",
        "        encoder = models.alexnet(pretrained=use_pretrained)\n",
        "        base_model = nn.Sequential(\n",
        "        encoder.features,\n",
        "        \n",
        "        )\n",
        "        dim = list(base_model.parameters())[-1].shape[0]  # last channels (512)\n",
        "        \n",
        "\n",
        "    elif model_name == \"vgg16\":\n",
        "        \"\"\" vgg16\n",
        "        \"\"\"\n",
        "        encoder = models.vgg16(pretrained=use_pretrained)\n",
        "        base_model = nn.Sequential(\n",
        "        encoder.features,\n",
        "        \n",
        "        )\n",
        "        dim = list(base_model.parameters())[-1].shape[0]  # last channels (512)\n",
        "    elif model_name == \"vgg19\":\n",
        "        \"\"\" vgg19\n",
        "        \"\"\"\n",
        "        encoder = models.vgg19(pretrained=use_pretrained)\n",
        "        base_model = nn.Sequential(\n",
        "        encoder.features,\n",
        "        \n",
        "        )\n",
        "        dim = list(base_model.parameters())[-1].shape[0]  # last channels (512)\n",
        "  \n",
        "    elif model_name == \"densenet121\":\n",
        "        \"\"\" densenet121\n",
        "        \"\"\"\n",
        "        encoder = models.densenet121(pretrained=use_pretrained)\n",
        "        base_model = nn.Sequential(\n",
        "        encoder.features,\n",
        "        \n",
        "        )\n",
        "        dim = list(base_model.parameters())[-1].shape[0]  # last channels (512)\n",
        "        \n",
        "    elif model_name == \"densenet161\":\n",
        "        \"\"\" densenet161\n",
        "        \"\"\"\n",
        "        encoder = models.densenet161(pretrained=use_pretrained)\n",
        "        base_model = nn.Sequential(\n",
        "        encoder.features,\n",
        "        \n",
        "        )\n",
        "        dim = list(base_model.parameters())[-1].shape[0]  # last channels (512)\n",
        "        \n",
        "    elif model_name == 'mobilenet':\n",
        "        \"\"\" mobilenet_v2\n",
        "        \"\"\"\n",
        "        encoder = models.mobilenet_v2(pretrained=use_pretrained)\n",
        "        base_model = nn.Sequential(\n",
        "        encoder.features,\n",
        "\n",
        "        )\n",
        "        dim = list(base_model.parameters())[-1].shape[0]  # last channels (512)\n",
        "    elif model_name == 'squeezenet':\n",
        "        \"\"\" squeezenet\n",
        "        \"\"\"\n",
        "        encoder = models.squeezenet.squeezenet1_1(pretrained=use_pretrained)\n",
        "        base_model = nn.Sequential(\n",
        "        encoder.features,\n",
        "\n",
        "        )\n",
        "        dim = list(base_model.parameters())[-1].shape[0]  # last channels (512)\n",
        "\n",
        "    else:\n",
        "        print(\"Invalid model name, exiting...\")\n",
        "        \n",
        "\n",
        "    return base_model, dim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RQvaki_q6HC",
        "colab_type": "code",
        "outputId": "c7c998fd-1390-45e3-e086-f746a02f3f8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "# model_list = ['resnet18','resnet50','resnet101','alexnet','vgg16','vgg19','densenet121','densenet161','mobilenet','squeezenet']\n",
        "base_model_dict = {}\n",
        "model_list = [model_name]\n",
        "for i in model_list:\n",
        "  base_model,dim =initialize_model(i,use_pretrained=True)\n",
        "  print(i,'is completed , dim is ',dim)\n",
        "  base_model_dict[i]=[base_model,dim]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/checkpoints/resnet18-5c106cde.pth\n",
            "100%|██████████| 46827520/46827520 [00:02<00:00, 19875320.82it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "resnet18 is completed , dim is  512\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gy5e4FF3aWve",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_name = model_name\n",
        "base_model = base_model_dict[model_name][0]\n",
        "dim = base_model_dict[model_name][1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPT97DFbsK7w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define model for embedding\n",
        "net_vlad = NetVLAD(num_clusters=7, dim=dim, alpha=1.0)\n",
        "model = EmbedNet(base_model, net_vlad).cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxHsPHtrsp4-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define loss\n",
        "criterion = HardTripletLoss(margin=0.1).cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJkRFjLlMEcR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EP9gRLjdhGs",
        "colab_type": "code",
        "outputId": "28f2e309-720a-4535-cc73-26600e607465",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "state_dict = torch.load(model_load_path)\n",
        "model.load_state_dict(state_dict)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_XvVkEXTd0sq",
        "colab": {}
      },
      "source": [
        "transforms = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.Resize((128,128)),                    #이미지의 크기\n",
        "#     torchvision.transforms.ColorJitter(hue=.05, saturation=.05), #사진의 밝기를 변화시키는 코드\n",
        "#     torchvision.transforms.RandomHorizontalFlip(),               #죄우 대칭을 위한 코드\n",
        "    torchvision.transforms.ToTensor()\n",
        "    \n",
        "])\n",
        "\n",
        "query_imagenet_data = torchvision.datasets.ImageFolder(test_path, transform=transforms)\n",
        "query_data_loader = torch.utils.data.DataLoader(query_imagenet_data,\n",
        "                                          shuffle=True,\n",
        "                                          batch_size=366,\n",
        "                                          num_workers=0)\n",
        "\n",
        "\n",
        "## total 5 classes : 81 images per class\n",
        "refer_imagenet_data = torchvision.datasets.ImageFolder(test_path, transform=transforms)\n",
        "refer_data_loader = torch.utils.data.DataLoader(refer_imagenet_data,\n",
        "                                          shuffle=False,\n",
        "                                          batch_size=366,\n",
        "                                          num_workers=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzQOlK8ItYqt",
        "colab_type": "text"
      },
      "source": [
        "## Reference Data(test):\n",
        "\n",
        "{'AI': 14, \n",
        "\n",
        " 'Clock tower': 22,\n",
        " \n",
        " 'Front door Child': 14,\n",
        " \n",
        " 'Front door Sejong': 24,\n",
        " \n",
        " 'Stone statue': 7}\n",
        " \n",
        " ## Reference Data(train):\n",
        "\n",
        "{'AI': 101, \n",
        "\n",
        " 'Clock tower': 41,\n",
        " \n",
        " 'Front door Child': 83,\n",
        " \n",
        " 'Front door Sejong': 46,\n",
        " \n",
        " 'Stone statue': 95}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EyzjxYK2OGCj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "refer_np =None\n",
        "refer_label = None\n",
        "query_np = None\n",
        "query_label = None\n",
        "\n",
        "for query_image,query_label in query_data_loader :\n",
        "  query_output = model(query_image.cuda()) \n",
        "  X_query = query_output.cpu().data.numpy()\n",
        "  query_label = query_label.cpu().data.numpy()\n",
        "  query_np = query_image.cpu().data.numpy()\n",
        "\n",
        "for refer_image,refer_label in refer_data_loader :\n",
        "  refer_output = model(refer_image.cuda()) \n",
        "  X_refer = refer_output.cpu().data.numpy()\n",
        "  refer_label = refer_label.cpu().data.numpy()\n",
        "  refer_np = refer_image.cpu().data.numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DsQnnp8keLTJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# query_img = np.transpose(query_np, (0, 2, 3, 1))\n",
        "# plt.figure(figsize=(5,5))\n",
        "# plt.axis('off')\n",
        "# plt.imshow(query_img[select_idx])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8F7TPtmrh0CT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.neighbors import NearestNeighbors\n",
        "nbrs = NearestNeighbors(n_neighbors=81, algorithm ='ball_tree').fit(X_refer) # X_refer shape (batch size , dimension)\n",
        "distances, indices = nbrs.kneighbors(X_query)   # X_query shape (batch_size, dimension)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqOE4d4nIJdP",
        "colab_type": "code",
        "outputId": "d5e886a6-7baf-4a4f-a6eb-55f00a60d30b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(X_query.shape)  # query vector shape : batch size, dimension\n",
        "print(query_np.shape)  # query numpy shape : batch size , channel , height, width\n",
        "print(query_label.shape)   # query label shape : batch size[class idx] "
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(81, 3584)\n",
            "(81, 3, 128, 128)\n",
            "(81,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3XtUIv7OVAw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "count_to_class ={}\n",
        "for i in refer_label:\n",
        "  if not i in count_to_class:\n",
        "    count_to_class[i]=1\n",
        "  else:\n",
        "    count_to_class[i]+=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CU6sLNOsO8cD",
        "colab_type": "code",
        "outputId": "8a1cfaca-37a2-4dfd-e4f6-0aa90bf3d3fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "count_to_class"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 14, 1: 22, 2: 14, 3: 24, 4: 7}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iewe0Qzs0VFG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# y_true : label(interger), y_pred : label(list)\n",
        "def get_TFtable(y_true,y_pred):\n",
        "  table = []\n",
        "  TP =[]\n",
        "  FP = []\n",
        "  for i in y_pred:\n",
        "    if i==y_true:\n",
        "      table.append('true')\n",
        "    else:\n",
        "      table.append('false')\n",
        "  return table\n",
        "\n",
        "def evaluateAP(y_true, y_pred):\n",
        "  N_R = len(y_pred) \n",
        "#   print('image are retrieved N : {}'.format(N_R))\n",
        "  Rank_1 = None\n",
        "  P_5 = None\n",
        "  P_10 = None\n",
        "  RP_half = None\n",
        "  \n",
        "  s1 = 0\n",
        "  s2 = 0\n",
        "  s3 = 0 \n",
        "  s4 = 0\n",
        "  \n",
        "  tf_table=get_TFtable(y_true,y_pred)\n",
        "  reverse_table = tf_table.copy()\n",
        "  reverse_table.reverse()\n",
        "  index_T=len(reverse_table)-reverse_table.index('true')-1 #table의 마지막 TP index\n",
        "  K = count_to_class[y_true]\n",
        "  count_TP =0\n",
        "  sum_precision = 0\n",
        "  recall = 0\n",
        "  precision = 0\n",
        "  for i in range(0,index_T+1):\n",
        "    if precision>=0.5 and RP_half == None:\n",
        "      RP_half = recall\n",
        "\n",
        "#       print('recall at precision 0.5 : {}'.format(RP_half))\n",
        "    if i==6:\n",
        "        P_5 = precision\n",
        "#         print('precision{}@5 : {}'.format(i,P_5))\n",
        "#         print('R_{} precision : {}'.format(i,P_20))\n",
        "    if i==11:\n",
        "        P_10 = precision\n",
        "#         print('precision{}@10 : {}'.format(i,P_10))\n",
        "#         print('R_{} precision : {}'.format(i,P_50))\n",
        "    if tf_table[i]=='true':\n",
        "      if Rank_1 == None and i>=1:\n",
        "        Rank_1 = i\n",
        "\n",
        "#         print('Rank_1 index : {} '.format(Rank_1))\n",
        "        \n",
        "      count_TP+=1\n",
        "      recall = count_TP/index_T\n",
        "      precision = count_TP/(i+1)\n",
        "      sum_precision += precision\n",
        "\n",
        "#       print('t_i : {} , recall : {} , precision : {} '.format(i,recall,precision))\n",
        "  print('Average Precision query {} : {} '.format(y_true,sum_precision / K))\n",
        "  return sum_precision /K,Rank_1,P_5,RP_half\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CpBaffq6Zvj",
        "colab_type": "code",
        "outputId": "4ed3734a-c09f-411b-f62b-b01329d80444",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1394
        }
      },
      "source": [
        "import itertools\n",
        "\n",
        "sum_to_class ={}\n",
        "map_to_class = {}\n",
        "sumRank1_to_class ={}\n",
        "sumP5_to_class ={}\n",
        "sumP10_to_class ={}\n",
        "sumRPhalf_to_class ={}\n",
        "map2_to_class = {}\n",
        "map3_to_class = {}\n",
        "map5_to_class = {}\n",
        "\n",
        "\n",
        "total_MAP = 0\n",
        "sum_AP = 0\n",
        "for i in range(0,len(query_label)):\n",
        "  keys = np.ndarray.tolist(indices[i]) \n",
        "  values = np.ndarray.tolist(distances[i]) \n",
        "\n",
        "  find_dict = dict(zip(keys,values)) \n",
        "\n",
        "  similar = sorted(find_dict.items(), key=lambda find_dict: values)[:81]\n",
        "  similar_idx = [i[0] for i in similar]\n",
        "\n",
        "  y_true = query_label[i]\n",
        "#   print('query label : ',y_true)\n",
        "  \n",
        "  y_pred = [refer_label[i] for i in similar_idx]\n",
        "#   print('retrieval label : ',y_pred)\n",
        "  \n",
        "  AP,s1,s2,s4=evaluateAP(y_true,y_pred)\n",
        "#   print(s1,s2,s4)\n",
        "  sum_AP+=AP\n",
        "  if not y_true in sum_to_class.keys():\n",
        "    sum_to_class[y_true]=AP\n",
        "  else:\n",
        "    sum_to_class[y_true]+=AP\n",
        "  if not y_true in sumRank1_to_class.keys():\n",
        "    sumRank1_to_class[y_true]=s1\n",
        "  else:\n",
        "    sumRank1_to_class[y_true]+=s1\n",
        "  if not y_true in sumP5_to_class.keys():\n",
        "    sumP5_to_class[y_true]=s2\n",
        "  else:\n",
        "#     print(s2)\n",
        "    sumP5_to_class[y_true]+=s2\n",
        "\n",
        "  if not y_true in sumRPhalf_to_class.keys():\n",
        "    sumRPhalf_to_class[y_true]=s4\n",
        "  else:\n",
        "    sumRPhalf_to_class[y_true]+=s4\n",
        "\n",
        "    \n",
        "total_MAP = sum_AP/len(query_label)\n",
        "for key,value in sum_to_class.items():\n",
        "  map_to_class[key]=sum_to_class[key]/count_to_class[key]\n",
        "\n",
        "for key,value in sumRank1_to_class.items():\n",
        "  map2_to_class[key]=sumRank1_to_class[key]/count_to_class[key]\n",
        "  \n",
        "for key,value in sumP5_to_class.items():\n",
        "  map3_to_class[key]=sumP5_to_class[key]/count_to_class[key]\n",
        "  \n",
        "for key,value in sumRPhalf_to_class.items():\n",
        "  map5_to_class[key]=sumRPhalf_to_class[key]/count_to_class[key]\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average Precision query 2 : 0.5297665909705079 \n",
            "Average Precision query 3 : 0.7498153074413572 \n",
            "Average Precision query 1 : 0.9791375291375292 \n",
            "Average Precision query 1 : 0.9850756439961837 \n",
            "Average Precision query 1 : 0.29136847106520153 \n",
            "Average Precision query 0 : 1.0 \n",
            "Average Precision query 3 : 0.6812768404695922 \n",
            "Average Precision query 1 : 0.6546101636975652 \n",
            "Average Precision query 0 : 1.0 \n",
            "Average Precision query 2 : 0.6225112031230149 \n",
            "Average Precision query 1 : 0.40468785973420457 \n",
            "Average Precision query 2 : 0.4244018748677134 \n",
            "Average Precision query 1 : 0.9815184815184814 \n",
            "Average Precision query 2 : 0.41238430513640595 \n",
            "Average Precision query 2 : 0.630455342317154 \n",
            "Average Precision query 2 : 0.3405263750548034 \n",
            "Average Precision query 1 : 0.9517205208584518 \n",
            "Average Precision query 1 : 0.9380474917239624 \n",
            "Average Precision query 3 : 0.6703621593220598 \n",
            "Average Precision query 1 : 0.9848484848484849 \n",
            "Average Precision query 0 : 1.0 \n",
            "Average Precision query 4 : 0.8260204081632653 \n",
            "Average Precision query 2 : 0.6210959742748774 \n",
            "Average Precision query 3 : 0.5551608241310995 \n",
            "Average Precision query 4 : 0.9821428571428571 \n",
            "Average Precision query 1 : 0.9863071710897798 \n",
            "Average Precision query 2 : 0.658396847682562 \n",
            "Average Precision query 3 : 0.726575015025368 \n",
            "Average Precision query 4 : 0.9821428571428571 \n",
            "Average Precision query 2 : 0.5713807509421425 \n",
            "Average Precision query 3 : 0.5524649694615605 \n",
            "Average Precision query 0 : 1.0 \n",
            "Average Precision query 0 : 1.0 \n",
            "Average Precision query 0 : 1.0 \n",
            "Average Precision query 3 : 0.7683610445526706 \n",
            "Average Precision query 3 : 0.68487763126865 \n",
            "Average Precision query 0 : 1.0 \n",
            "Average Precision query 1 : 0.9837293388429752 \n",
            "Average Precision query 3 : 0.5678136609836314 \n",
            "Average Precision query 0 : 1.0 \n",
            "Average Precision query 1 : 0.9808612440191387 \n",
            "Average Precision query 2 : 0.6166863731910421 \n",
            "Average Precision query 2 : 0.28656589260844406 \n",
            "Average Precision query 1 : 0.969836293974225 \n",
            "Average Precision query 2 : 0.3615432315980454 \n",
            "Average Precision query 3 : 0.669782036011822 \n",
            "Average Precision query 1 : 0.9775757575757577 \n",
            "Average Precision query 1 : 0.9890282131661441 \n",
            "Average Precision query 0 : 1.0 \n",
            "Average Precision query 4 : 0.9821428571428571 \n",
            "Average Precision query 1 : 0.9806060606060606 \n",
            "Average Precision query 4 : 0.9821428571428571 \n",
            "Average Precision query 1 : 0.9823232323232323 \n",
            "Average Precision query 0 : 1.0 \n",
            "Average Precision query 3 : 0.5994656895106599 \n",
            "Average Precision query 2 : 0.6876003032792065 \n",
            "Average Precision query 3 : 0.7842651758442073 \n",
            "Average Precision query 3 : 0.671208936921495 \n",
            "Average Precision query 0 : 1.0 \n",
            "Average Precision query 1 : 0.4291501969140486 \n",
            "Average Precision query 3 : 0.7401717303348502 \n",
            "Average Precision query 1 : 0.9806060606060606 \n",
            "Average Precision query 3 : 0.5767957659866296 \n",
            "Average Precision query 3 : 0.6296758302471165 \n",
            "Average Precision query 0 : 1.0 \n",
            "Average Precision query 4 : 0.9821428571428571 \n",
            "Average Precision query 3 : 0.6706718905943663 \n",
            "Average Precision query 3 : 0.6607286112079858 \n",
            "Average Precision query 0 : 1.0 \n",
            "Average Precision query 2 : 0.5884003074220466 \n",
            "Average Precision query 3 : 0.7490201103473182 \n",
            "Average Precision query 3 : 0.5586965427596768 \n",
            "Average Precision query 3 : 0.6778731444262697 \n",
            "Average Precision query 1 : 0.9868035190615836 \n",
            "Average Precision query 4 : 0.9821428571428571 \n",
            "Average Precision query 1 : 0.9873251748251749 \n",
            "Average Precision query 0 : 1.0 \n",
            "Average Precision query 1 : 0.984577922077922 \n",
            "Average Precision query 3 : 0.5611150246265404 \n",
            "Average Precision query 3 : 0.6577642403749383 \n",
            "Average Precision query 3 : 0.6353475343769389 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQTzSwAkRNFa",
        "colab_type": "code",
        "outputId": "89e888a9-33d7-4adf-93ce-062abc105039",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "hist_dict={}\n",
        "hist_list =[]\n",
        "for name, idx in refer_imagenet_data.class_to_idx.items():\n",
        "  hist_dict = {'base_model':model_name,'epochs':epochs,'batch_size':batch_size,'class_name':name,'map_to_class':map_to_class[idx],'count_to_class':count_to_class[idx],'Rank1_to_class':map2_to_class[idx],'P5_to_class':map3_to_class[idx],'RP_0.5':map5_to_class[idx]}\n",
        "  hist_list.append(hist_dict)\n",
        "  print('base model name : {} , epoch : {}, batch size : {} , class name : {} , Mean Average Precision to class : {} , query counts to class : {}, {}, {} ,{} '.format(hist_dict['base_model'],hist_dict['epochs'] ,hist_dict['batch_size'],hist_dict['class_name'],hist_dict['map_to_class'],hist_dict['count_to_class'],hist_dict['Rank1_to_class'],hist_dict['P5_to_class'],hist_dict['RP_0.5']))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "base model name : resnet18 , epoch : 50, batch size : 256 , class name : AI , Mean Average Precision to class : 1.0 , query counts to class : 14, 1.0, 1.0 ,0.0769230769230769 \n",
            "base model name : resnet18 , epoch : 50, batch size : 256 , class name : Clock tower , Mean Average Precision to class : 0.8813520378028258 , query counts to class : 22, 1.6818181818181819, 1.0 ,0.031401239593915505 \n",
            "base model name : resnet18 , epoch : 50, batch size : 256 , class name : Front door Child , Mean Average Precision to class : 0.5251225266048548 , query counts to class : 14, 3.0, 0.7452380952380953 ,0.026315798637227206 \n",
            "base model name : resnet18 , epoch : 50, batch size : 256 , class name : Front door Sejong , Mean Average Precision to class : 0.6583037381761169 , query counts to class : 24, 1.4166666666666667, 0.796527777777778 ,0.023565038056725423 \n",
            "base model name : resnet18 , epoch : 50, batch size : 256 , class name : Stone statue , Mean Average Precision to class : 0.9598396501457724 , query counts to class : 7, 1.1428571428571428, 0.9761904761904763 ,0.14285714285714282 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5BMRAXCFdyYb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fig=plt.figure(figsize=(16, 16))\n",
        "# columns = 5\n",
        "# rows = 20\n",
        "# ax = []\n",
        "\n",
        "# idx = 0\n",
        "# for i in range(rows):\n",
        "#   for j in similar_idx:\n",
        "#     idx+=1\n",
        "#     ax.append( fig.add_subplot(rows, columns, idx) )\n",
        "#     ax[-1].set_title(\"top :\"+str(idx))  # set title\n",
        "#     plt.imshow(refer_img[j])\n",
        "\n",
        "# plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzbkPtYtmM6c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "\n",
        "with open(history_path, 'a') as f:  # Just use 'w' mode in 3.x\n",
        "  for i in range(0,len(hist_list)):\n",
        "    w = csv.DictWriter(f, hist_list[i].keys())\n",
        "    if i==0:\n",
        "      w.writeheader()\n",
        "    w.writerow(hist_list[i])\n",
        "  f.close()\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}