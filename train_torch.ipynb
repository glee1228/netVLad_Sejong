{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/glee1228/netVLad_keras/blob/master/train_torch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVFa5HXlsEK1",
        "colab_type": "code",
        "outputId": "d4780a6e-b444-497b-a2fd-f2f1fec72e33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from torch.autograd import Variable\n",
        "from torchvision import models\n",
        "\n",
        "from tensorflow import keras\n",
        "from keras.preprocessing import image\n",
        "\n",
        "import PIL\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import svm, datasets, metrics"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8LDbLsXHgtK",
        "colab_type": "code",
        "outputId": "b6779742-61a7-4cb3-b465-49b0b494dafb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "torch.manual_seed(777)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fc9116b8810>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ekD3HEdBzND",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip install tensorboardcolab\n",
        "# from tensorboardcolab import TensorBoardColab\n",
        "# tb = TensorBoardColab()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqsULtEewAJy",
        "colab_type": "code",
        "outputId": "cb29827d-909a-4795-f193-9bde01897602",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "if os.path.exists('/content/gdrive')==False:\n",
        "    drive.mount('/content/gdrive')\n",
        "    print('Google Drive is mounted\\n')\n",
        "else:\n",
        "    print('Google Drive is already mounted\\n')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Google Drive is already mounted\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVXFtGxtVGPx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ckpt_path = '/content/gdrive/My Drive/AILeader_Dataset/ckpt'\n",
        "train_path = '/content/gdrive/My Drive/AILeader_Dataset/NEW train'\n",
        "test_path = '/content/gdrive/My Drive/AILeader_Dataset/test'\n",
        "history_path = '/content/gdrive/My Drive/AILeader_Dataset/history.csv'\n",
        "\n",
        "epochs = 20\n",
        "batch_size = 128\n",
        "model_name = 'resnet18' #'resnet18','resnet50','resnet101','alexnet','vgg16','vgg19','densenet121','densenet161','mobilenet','squeezenet'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ByNd9eMsFYn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NetVLAD(nn.Module):\n",
        "    \"\"\"NetVLAD layer implementation\"\"\"\n",
        "\n",
        "    def __init__(self, num_clusters=7, dim=128, alpha=100.0,\n",
        "                 normalize_input=True):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            num_clusters : int\n",
        "                The number of clusters\n",
        "            dim : int\n",
        "                Dimension of descriptors\n",
        "            alpha : float\n",
        "                Parameter of initialization. Larger value is harder assignment.\n",
        "            normalize_input : bool\n",
        "                If true, descriptor-wise L2 normalization is applied to input.\n",
        "        \"\"\"\n",
        "        super(NetVLAD, self).__init__()\n",
        "        self.num_clusters = num_clusters\n",
        "        self.dim = dim\n",
        "        self.alpha = alpha\n",
        "        self.normalize_input = normalize_input\n",
        "        self.conv = nn.Conv2d(dim, num_clusters, kernel_size=(1, 1), bias=True)\n",
        "        self.centroids = nn.Parameter(torch.rand(num_clusters, dim))\n",
        "        self._init_params()\n",
        "\n",
        "    def _init_params(self):\n",
        "        self.conv.weight = nn.Parameter(\n",
        "            (2.0 * self.alpha * self.centroids).unsqueeze(-1).unsqueeze(-1)\n",
        "        )\n",
        "        self.conv.bias = nn.Parameter(\n",
        "            - self.alpha * self.centroids.norm(dim=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        N, C = x.shape[:2]\n",
        "\n",
        "        if self.normalize_input:\n",
        "            x = F.normalize(x, p=2, dim=1)  # across descriptor dim\n",
        "\n",
        "        # soft-assignment\n",
        "        soft_assign = self.conv(x).view(N, self.num_clusters, -1)\n",
        "        soft_assign = F.softmax(soft_assign, dim=1)\n",
        "\n",
        "        x_flatten = x.view(N, C, -1)\n",
        "        \n",
        "        # calculate residuals to each clusters\n",
        "        residual = x_flatten.expand(self.num_clusters, -1, -1, -1).permute(1, 0, 2, 3) - \\\n",
        "            self.centroids.expand(x_flatten.size(-1), -1, -1).permute(1, 2, 0).unsqueeze(0)\n",
        "        residual *= soft_assign.unsqueeze(2)\n",
        "        vlad = residual.sum(dim=-1)\n",
        "\n",
        "        vlad = F.normalize(vlad, p=2, dim=2)  # intra-normalization\n",
        "        vlad = vlad.view(x.size(0), -1)  # flatten\n",
        "        vlad = F.normalize(vlad, p=2, dim=1)  # L2 normalize\n",
        "\n",
        "        return vlad\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKzKKFWksfVT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EmbedNet(nn.Module):\n",
        "    def __init__(self, base_model, net_vlad):\n",
        "        super(EmbedNet, self).__init__()\n",
        "        self.base_model = base_model\n",
        "        self.net_vlad = net_vlad\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.base_model(x)\n",
        "        embedded_x = self.net_vlad(x)\n",
        "        return embedded_x\n",
        "      \n",
        "class TripletNet(nn.Module):\n",
        "    def __init__(self, embed_net):\n",
        "        super(TripletNet, self).__init__()\n",
        "        self.embed_net = embed_net\n",
        "\n",
        "    def forward(self, a, p, n):\n",
        "        embedded_a = self.embed_net(a)\n",
        "        embedded_p = self.embed_net(p)\n",
        "        embedded_n = self.embed_net(n)\n",
        "        return embedded_a, embedded_p, embedded_n\n",
        "\n",
        "    def feature_extract(self, x):\n",
        "        return self.embed_net(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fD_yKdlMsZai",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class HardTripletLoss(nn.Module):\n",
        "    \"\"\"Hard/Hardest Triplet Loss\n",
        "    (pytorch implementation of https://omoindrot.github.io/triplet-loss)\n",
        "    For each anchor, we get the hardest positive and hardest negative to form a triplet.\n",
        "    \"\"\"\n",
        "    def __init__(self, margin=0.1, hardest=False, squared=False):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            margin: margin for triplet loss\n",
        "            hardest: If true, loss is considered only hardest triplets.\n",
        "            squared: If true, output is the pairwise squared euclidean distance matrix.\n",
        "                If false, output is the pairwise euclidean distance matrix.\n",
        "        \"\"\"\n",
        "        super(HardTripletLoss, self).__init__()\n",
        "        self.margin = margin\n",
        "        self.hardest = hardest\n",
        "        self.squared = squared\n",
        "\n",
        "    def forward(self, embeddings, labels):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            labels: labels of the batch, of size (batch_size,)\n",
        "            embeddings: tensor of shape (batch_size, embed_dim)\n",
        "        Returns:\n",
        "            triplet_loss: scalar tensor containing the triplet loss\n",
        "        \"\"\"\n",
        "        pairwise_dist = _pairwise_distance(embeddings, squared=self.squared)\n",
        "\n",
        "        if self.hardest:\n",
        "            # Get the hardest positive pairs\n",
        "            mask_anchor_positive = _get_anchor_positive_triplet_mask(labels).float()\n",
        "            valid_positive_dist = pairwise_dist * mask_anchor_positive\n",
        "            hardest_positive_dist, _ = torch.max(valid_positive_dist, dim=1, keepdim=True)\n",
        "\n",
        "            # Get the hardest negative pairs\n",
        "            mask_anchor_negative = _get_anchor_negative_triplet_mask(labels).float()\n",
        "            max_anchor_negative_dist, _ = torch.max(pairwise_dist, dim=1, keepdim=True)\n",
        "            anchor_negative_dist = pairwise_dist + max_anchor_negative_dist * (\n",
        "                    1.0 - mask_anchor_negative)\n",
        "            hardest_negative_dist, _ = torch.min(anchor_negative_dist, dim=1, keepdim=True)\n",
        "\n",
        "            # Combine biggest d(a, p) and smallest d(a, n) into final triplet loss\n",
        "            triplet_loss = F.relu(hardest_positive_dist - hardest_negative_dist + 0.1)\n",
        "            triplet_loss = torch.mean(triplet_loss)\n",
        "        else:\n",
        "            anc_pos_dist = pairwise_dist.unsqueeze(dim=2)\n",
        "            anc_neg_dist = pairwise_dist.unsqueeze(dim=1)\n",
        "\n",
        "            # Compute a 3D tensor of size (batch_size, batch_size, batch_size)\n",
        "            # triplet_loss[i, j, k] will contain the triplet loss of anc=i, pos=j, neg=k\n",
        "            # Uses broadcasting where the 1st argument has shape (batch_size, batch_size, 1)\n",
        "            # and the 2nd (batch_size, 1, batch_size)\n",
        "            loss = anc_pos_dist - anc_neg_dist + self.margin\n",
        "\n",
        "            mask = _get_triplet_mask(labels).float()\n",
        "            triplet_loss = loss * mask\n",
        "\n",
        "            # Remove negative losses (i.e. the easy triplets)\n",
        "            triplet_loss = F.relu(triplet_loss)\n",
        "\n",
        "            # Count number of hard triplets (where triplet_loss > 0)\n",
        "            hard_triplets = torch.gt(triplet_loss, 1e-16).float()\n",
        "            num_hard_triplets = torch.sum(hard_triplets)\n",
        "\n",
        "            triplet_loss = torch.sum(triplet_loss) / (num_hard_triplets + 1e-16)\n",
        "\n",
        "        return triplet_loss\n",
        "\n",
        "\n",
        "def _pairwise_distance(x, squared=False, eps=1e-16):\n",
        "    # Compute the 2D matrix of distances between all the embeddings.\n",
        "\n",
        "    cor_mat = torch.matmul(x, x.t())\n",
        "    norm_mat = cor_mat.diag()\n",
        "    distances = norm_mat.unsqueeze(1) - 2 * cor_mat + norm_mat.unsqueeze(0)\n",
        "    distances = F.relu(distances)\n",
        "\n",
        "    if not squared:\n",
        "        mask = torch.eq(distances, 0.0).float()\n",
        "        distances = distances + mask * eps\n",
        "        distances = torch.sqrt(distances)\n",
        "        distances = distances * (1.0 - mask)\n",
        "\n",
        "    return distances\n",
        "\n",
        "\n",
        "def _get_anchor_positive_triplet_mask(labels):\n",
        "    # Return a 2D mask where mask[a, p] is True iff a and p are distinct and have same label.\n",
        "\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    indices_not_equal = torch.eye(labels.shape[0]).to(device).byte() ^ 1\n",
        "\n",
        "    # Check if labels[i] == labels[j]\n",
        "    labels_equal = torch.unsqueeze(labels, 0) == torch.unsqueeze(labels, 1)\n",
        "\n",
        "    mask = indices_not_equal * labels_equal\n",
        "\n",
        "    return mask\n",
        "\n",
        "\n",
        "def _get_anchor_negative_triplet_mask(labels):\n",
        "    # Return a 2D mask where mask[a, n] is True iff a and n have distinct labels.\n",
        "\n",
        "    # Check if labels[i] != labels[k]\n",
        "    labels_equal = torch.unsqueeze(labels, 0) == torch.unsqueeze(labels, 1)\n",
        "    mask = labels_equal ^ 1\n",
        "\n",
        "    return mask\n",
        "\n",
        "\n",
        "def _get_triplet_mask(labels):\n",
        "    \"\"\"Return a 3D mask where mask[a, p, n] is True iff the triplet (a, p, n) is valid.\n",
        "    A triplet (i, j, k) is valid if:\n",
        "        - i, j, k are distinct\n",
        "        - labels[i] == labels[j] and labels[i] != labels[k]\n",
        "    \"\"\"\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Check that i, j and k are distinct\n",
        "    indices_not_same = torch.eye(labels.shape[0]).to(device).byte() ^ 1\n",
        "    i_not_equal_j = torch.unsqueeze(indices_not_same, 2)\n",
        "    i_not_equal_k = torch.unsqueeze(indices_not_same, 1)\n",
        "    j_not_equal_k = torch.unsqueeze(indices_not_same, 0)\n",
        "    distinct_indices = i_not_equal_j * i_not_equal_k * j_not_equal_k\n",
        "\n",
        "    # Check if labels[i] == labels[j] and labels[i] != labels[k]\n",
        "    label_equal = torch.eq(torch.unsqueeze(labels, 0), torch.unsqueeze(labels, 1))\n",
        "    i_equal_j = torch.unsqueeze(label_equal, 2)\n",
        "    i_equal_k = torch.unsqueeze(label_equal, 1)\n",
        "    valid_labels = i_equal_j * (i_equal_k ^ 1)\n",
        "\n",
        "    mask = distinct_indices * valid_labels   # Combine the two masks\n",
        "\n",
        "    return mask"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qn7-PPiWqwak",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initialize_model(model_name, use_pretrained=True):\n",
        "    # Initialize these variables which will be set in this if statement. Each of these\n",
        "    #   variables is model specific.\n",
        "    base_model = None\n",
        "    dim = 0\n",
        "\n",
        "    if model_name == \"resnet18\":\n",
        "        \"\"\" Resnet18\n",
        "        \"\"\"\n",
        "        encoder = models.resnet18(pretrained=use_pretrained)\n",
        "        base_model = nn.Sequential(\n",
        "        encoder.conv1,\n",
        "        encoder.bn1,\n",
        "        encoder.relu,\n",
        "        encoder.maxpool,\n",
        "        encoder.layer1,\n",
        "        encoder.layer2,\n",
        "        encoder.layer3,\n",
        "        encoder.layer4,\n",
        "        )\n",
        "        dim = list(base_model.parameters())[-1].shape[0]  # last channels (512)\n",
        "        \n",
        "    elif model_name == \"resnet50\":\n",
        "        \"\"\" Resnet50\n",
        "        \"\"\"\n",
        "        encoder = models.resnet50(pretrained=use_pretrained)\n",
        "        base_model = nn.Sequential(\n",
        "        encoder.conv1,\n",
        "        encoder.bn1,\n",
        "        encoder.relu,\n",
        "        encoder.maxpool,\n",
        "        encoder.layer1,\n",
        "        encoder.layer2,\n",
        "        encoder.layer3,\n",
        "        encoder.layer4,\n",
        "        )\n",
        "        dim = list(base_model.parameters())[-1].shape[0]  # last channels (512)\n",
        "    elif model_name == \"resnet101\":\n",
        "        \"\"\" Resnet101\n",
        "        \"\"\"\n",
        "        encoder = models.resnet101(pretrained=use_pretrained)\n",
        "        base_model = nn.Sequential(\n",
        "        encoder.conv1,\n",
        "        encoder.bn1,\n",
        "        encoder.relu,\n",
        "        encoder.maxpool,\n",
        "        encoder.layer1,\n",
        "        encoder.layer2,\n",
        "        encoder.layer3,\n",
        "        encoder.layer4,\n",
        "        )\n",
        "        dim = list(base_model.parameters())[-1].shape[0]  # last channels (512)\n",
        "        \n",
        "    elif model_name == \"alexnet\":\n",
        "        \"\"\" alexnet\n",
        "        \"\"\"\n",
        "        encoder = models.alexnet(pretrained=use_pretrained)\n",
        "        base_model = nn.Sequential(\n",
        "        encoder.features,\n",
        "        \n",
        "        )\n",
        "        dim = list(base_model.parameters())[-1].shape[0]  # last channels (512)\n",
        "        \n",
        "\n",
        "    elif model_name == \"vgg16\":\n",
        "        \"\"\" vgg16\n",
        "        \"\"\"\n",
        "        encoder = models.vgg16(pretrained=use_pretrained)\n",
        "        base_model = nn.Sequential(\n",
        "        encoder.features,\n",
        "        \n",
        "        )\n",
        "        dim = list(base_model.parameters())[-1].shape[0]  # last channels (512)\n",
        "    elif model_name == \"vgg19\":\n",
        "        \"\"\" vgg19\n",
        "        \"\"\"\n",
        "        encoder = models.vgg19(pretrained=use_pretrained)\n",
        "        base_model = nn.Sequential(\n",
        "        encoder.features,\n",
        "        \n",
        "        )\n",
        "        dim = list(base_model.parameters())[-1].shape[0]  # last channels (512)\n",
        "  \n",
        "    elif model_name == \"densenet121\":\n",
        "        \"\"\" densenet121\n",
        "        \"\"\"\n",
        "        encoder = models.densenet121(pretrained=use_pretrained)\n",
        "        base_model = nn.Sequential(\n",
        "        encoder.features,\n",
        "        \n",
        "        )\n",
        "        dim = list(base_model.parameters())[-1].shape[0]  # last channels (512)\n",
        "        \n",
        "    elif model_name == \"densenet161\":\n",
        "        \"\"\" densenet161\n",
        "        \"\"\"\n",
        "        encoder = models.densenet161(pretrained=use_pretrained)\n",
        "        base_model = nn.Sequential(\n",
        "        encoder.features,\n",
        "        \n",
        "        )\n",
        "        dim = list(base_model.parameters())[-1].shape[0]  # last channels (512)\n",
        "        \n",
        "    elif model_name == 'mobilenet':\n",
        "        \"\"\" mobilenet_v2\n",
        "        \"\"\"\n",
        "        encoder = models.mobilenet_v2(pretrained=use_pretrained)\n",
        "        base_model = nn.Sequential(\n",
        "        encoder.features,\n",
        "\n",
        "        )\n",
        "        dim = list(base_model.parameters())[-1].shape[0]  # last channels (512)\n",
        "    elif model_name == 'squeezenet':\n",
        "        \"\"\" squeezenet\n",
        "        \"\"\"\n",
        "        encoder = models.squeezenet.squeezenet1_1(pretrained=use_pretrained)\n",
        "        base_model = nn.Sequential(\n",
        "        encoder.features,\n",
        "\n",
        "        )\n",
        "        dim = list(base_model.parameters())[-1].shape[0]  # last channels (512)\n",
        "\n",
        "    else:\n",
        "        print(\"Invalid model name, exiting...\")\n",
        "        \n",
        "\n",
        "    return base_model, dim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RQvaki_q6HC",
        "colab_type": "code",
        "outputId": "37ade803-cd97-4af2-a5ce-6c08bab037ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "model_list = ['resnet18','resnet50','resnet101','alexnet','vgg16','vgg19','densenet121','densenet161','mobilenet','squeezenet']\n",
        "base_model_dict = {}\n",
        "\n",
        "for i in model_list:\n",
        "  base_model,dim =initialize_model(i,use_pretrained=True)\n",
        "  print(i,'is completed , dim is ',dim)\n",
        "  base_model_dict[i]=[base_model,dim]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "resnet18 is completed , dim is  512\n",
            "resnet50 is completed , dim is  2048\n",
            "resnet101 is completed , dim is  2048\n",
            "alexnet is completed , dim is  256\n",
            "vgg16 is completed , dim is  512\n",
            "vgg19 is completed , dim is  512\n",
            "densenet121 is completed , dim is  1024\n",
            "densenet161 is completed , dim is  2208\n",
            "mobilenet is completed , dim is  1280\n",
            "squeezenet is completed , dim is  256\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gy5e4FF3aWve",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_name = model_name\n",
        "base_model = base_model_dict[model_name][0]\n",
        "dim = base_model_dict[model_name][1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPT97DFbsK7w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define model for embedding\n",
        "net_vlad = NetVLAD(num_clusters=7, dim=dim, alpha=1.0)\n",
        "model = EmbedNet(base_model, net_vlad).cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxHsPHtrsp4-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define loss\n",
        "criterion = HardTripletLoss(margin=0.1).cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJkRFjLlMEcR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrfD-ILt-2BN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transforms = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.Resize((128,128)),                    #이미지의 크기\n",
        "#     torchvision.transforms.ColorJitter(hue=.05, saturation=.05), #사진의 밝기를 변화시키는 코드\n",
        "#     torchvision.transforms.RandomHorizontalFlip(),               #죄우 대칭을 위한 코드\n",
        "    torchvision.transforms.ToTensor()\n",
        "    \n",
        "])\n",
        "\n",
        "train_imagenet_data = torchvision.datasets.ImageFolder(train_path, transform=transforms)\n",
        "train_data_loader = torch.utils.data.DataLoader(train_imagenet_data,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=True,\n",
        "                                          num_workers=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQPFdi7QL-uH",
        "colab_type": "code",
        "outputId": "45300362-971f-41c0-8c0b-bb4d24b62630",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "globaliter = 0\n",
        "last_ckpt_path = None\n",
        "for epoch in range(epochs):\n",
        "  print(epoch)\n",
        "  for batch_idx, (train_image,train_label) in enumerate(train_data_loader) :\n",
        "    output_train = model(train_image.cuda())\n",
        "    triplet_loss = criterion(output_train, train_label.cuda())\n",
        "    optimizer.zero_grad()\n",
        "    triplet_loss.backward(retain_graph=True)\n",
        "    optimizer.step()\n",
        "    print(epoch,globaliter,batch_idx,triplet_loss.item())\n",
        "    globaliter += 1\n",
        "  model_save_name = '{}_model_{}_{}.pt'.format(model_name,epoch,batch_size)\n",
        "  path = os.path.join(ckpt_path,model_save_name)\n",
        "  \n",
        "  torch.save(model.state_dict(), path)\n",
        "  last_ckpt_path = path"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "0 0 0 0.09524444490671158\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EP9gRLjdhGs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "state_dict = torch.load(last_ckpt_path)\n",
        "model.load_state_dict(state_dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_XvVkEXTd0sq",
        "colab": {}
      },
      "source": [
        "transforms = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.Resize((128,128)),                    #이미지의 크기\n",
        "#     torchvision.transforms.ColorJitter(hue=.05, saturation=.05), #사진의 밝기를 변화시키는 코드\n",
        "#     torchvision.transforms.RandomHorizontalFlip(),               #죄우 대칭을 위한 코드\n",
        "    torchvision.transforms.ToTensor()\n",
        "    \n",
        "])\n",
        "\n",
        "query_imagenet_data = torchvision.datasets.ImageFolder(test_path, transform=transforms)\n",
        "query_data_loader = torch.utils.data.DataLoader(query_imagenet_data,\n",
        "                                          shuffle=True,\n",
        "                                          batch_size=81,\n",
        "                                          num_workers=0)\n",
        "\n",
        "\n",
        "## total 5 classes : 81 images per class\n",
        "refer_imagenet_data = torchvision.datasets.ImageFolder(test_path, transform=transforms)\n",
        "refer_data_loader = torch.utils.data.DataLoader(refer_imagenet_data,\n",
        "                                          shuffle=False,\n",
        "                                          batch_size=81,\n",
        "                                          num_workers=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzQOlK8ItYqt",
        "colab_type": "text"
      },
      "source": [
        "## Reference Data:\n",
        "\n",
        "{'AI': 14, \n",
        "\n",
        " 'Clock tower': 22,\n",
        " \n",
        " 'Front door Child': 14,\n",
        " \n",
        " 'Front door Sejong': 24,\n",
        " \n",
        " 'Stone statue': 7}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EyzjxYK2OGCj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "refer_np =None\n",
        "refer_label = None\n",
        "query_np = None\n",
        "query_label = None\n",
        "\n",
        "for query_image,query_label in query_data_loader :\n",
        "  query_output = model(query_image.cuda()) \n",
        "  X_query = query_output.cpu().data.numpy()\n",
        "  query_label = query_label.cpu().data.numpy()\n",
        "  query_np = query_image.cpu().data.numpy()\n",
        "\n",
        "for refer_image,refer_label in refer_data_loader :\n",
        "  refer_output = model(refer_image.cuda()) \n",
        "  X_refer = refer_output.cpu().data.numpy()\n",
        "  refer_label = refer_label.cpu().data.numpy()\n",
        "  refer_np = refer_image.cpu().data.numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DsQnnp8keLTJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# query_img = np.transpose(query_np, (0, 2, 3, 1))\n",
        "# plt.figure(figsize=(5,5))\n",
        "# plt.axis('off')\n",
        "# plt.imshow(query_img[select_idx])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8F7TPtmrh0CT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.neighbors import NearestNeighbors\n",
        "nbrs = NearestNeighbors(n_neighbors=81, algorithm ='ball_tree').fit(X_refer) # X_refer shape (batch size , dimension)\n",
        "distances, indices = nbrs.kneighbors(X_query)   # X_query shape (batch_size, dimension)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqOE4d4nIJdP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(X_query.shape)  # query vector shape : batch size, dimension\n",
        "print(query_np.shape)  # query numpy shape : batch size , channel , height, width\n",
        "print(query_label.shape)   # query label shape : batch size[class idx] "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3XtUIv7OVAw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "count_to_class ={}\n",
        "for i in refer_label:\n",
        "  if not i in count_to_class:\n",
        "    count_to_class[i]=1\n",
        "  else:\n",
        "    count_to_class[i]+=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CU6sLNOsO8cD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "count_to_class"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iewe0Qzs0VFG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# y_true : label(interger), y_pred : label(list)\n",
        "def get_TFtable(y_true,y_pred):\n",
        "  table = []\n",
        "  TP =[]\n",
        "  FP = []\n",
        "  for i in y_pred:\n",
        "    if i==y_true:\n",
        "      table.append('true')\n",
        "    else:\n",
        "      table.append('false')\n",
        "  return table\n",
        "\n",
        "def evaluateAP(y_true, y_pred):\n",
        "  tf_table=get_TFtable(y_true,y_pred)\n",
        "  reverse_table = tf_table.copy()\n",
        "  reverse_table.reverse()\n",
        "  index_T=len(reverse_table)-reverse_table.index('true')-1 #table의 마지막 TP index\n",
        "  K = count_to_class[y_true]\n",
        "  count_TP =0\n",
        "  sum_precision = 0\n",
        "  for i in range(0,index_T+1):\n",
        "    if tf_table[i]=='true':\n",
        "      count_TP+=1\n",
        "      recall = count_TP/index_T\n",
        "      precision = count_TP/(i+1)\n",
        "      sum_precision += precision\n",
        "#       print('t_i : {} , recall : {} , precision : {} '.format(i,recall,precision))\n",
        "  print('Average Precision query {} : {} '.format(y_true,sum_precision / K))\n",
        "  return sum_precision /K\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CpBaffq6Zvj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import itertools\n",
        "\n",
        "sum_to_class ={}\n",
        "map_to_class = {}\n",
        "\n",
        "total_MAP = 0\n",
        "sum_AP = 0\n",
        "for i in range(0,len(query_label)):\n",
        "  keys = np.ndarray.tolist(indices[i]) \n",
        "  values = np.ndarray.tolist(distances[i]) \n",
        "\n",
        "  find_dict = dict(zip(keys,values)) \n",
        "\n",
        "  similar = sorted(find_dict.items(), key=lambda find_dict: values)[:81]\n",
        "  similar_idx = [i[0] for i in similar]\n",
        "\n",
        "  y_true = query_label[i]\n",
        "#   print('query label : ',y_true)\n",
        "  \n",
        "  y_pred = [refer_label[i] for i in similar_idx]\n",
        "#   print('retrieval label : ',y_pred)\n",
        "  \n",
        "  AP=evaluateAP(y_true,y_pred)\n",
        "  sum_AP+=AP\n",
        "  if not y_true in sum_to_class.keys():\n",
        "    sum_to_class[y_true]=AP\n",
        "  else:\n",
        "    sum_to_class[y_true]+=AP\n",
        "  \n",
        "\n",
        "total_MAP = sum_AP/len(query_label)\n",
        "for key,value in sum_to_class.items():\n",
        "  map_to_class[key]=sum_to_class[key]/count_to_class[key]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQTzSwAkRNFa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hist_dict={}\n",
        "hist_list =[]\n",
        "for name, idx in refer_imagenet_data.class_to_idx.items():\n",
        "  hist_dict = {'base_model':model_name,'epochs':epochs,'batch_size':batch_size,'class_name':name,'map_to_class':map_to_class[idx],'count_to_class':count_to_class[idx]}\n",
        "  hist_list.append(hist_dict)\n",
        "  print('base model name : {} , epoch : {}, batch size : {} , class name : {} , Mean Average Precision to class : {} , query counts to class : {}'.format(hist_dict['base_model'],hist_dict['epochs'] ,hist_dict['batch_size'],hist_dict['class_name'],hist_dict['map_to_class'],hist_dict['count_to_class']))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5BMRAXCFdyYb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fig=plt.figure(figsize=(16, 16))\n",
        "# columns = 5\n",
        "# rows = 20\n",
        "# ax = []\n",
        "\n",
        "# idx = 0\n",
        "# for i in range(rows):\n",
        "#   for j in similar_idx:\n",
        "#     idx+=1\n",
        "#     ax.append( fig.add_subplot(rows, columns, idx) )\n",
        "#     ax[-1].set_title(\"top :\"+str(idx))  # set title\n",
        "#     plt.imshow(refer_img[j])\n",
        "\n",
        "# plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzbkPtYtmM6c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "\n",
        "with open(history_path, 'a') as f:  # Just use 'w' mode in 3.x\n",
        "  for i in range(0,len(hist_list)):\n",
        "    w = csv.DictWriter(f, hist_list[i].keys())\n",
        "    if i==0:\n",
        "      w.writeheader()\n",
        "    w.writerow(hist_list[i])\n",
        "  f.close()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBIlIAtFWvF4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}